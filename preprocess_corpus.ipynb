{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 1 pickled file of a given event type\n",
    "event = 'file'\n",
    "file = os.path.join(SANDY_ATTR_PATH, f'corpus.{event}.pkl')\n",
    "\n",
    "corpus = pickle.load(open(file, \"rb\" ))\n",
    "attr = pickle.load(open(os.path.join(SANDY_ATTR_PATH, f'attr.{event}.pkl'), \"rb\" ))\n",
    "targets = attr['target_arr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APIs</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FltDecodeParameters FltDecodeParameters FltDec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>FltDecodeParameters FltDecodeParameters FltDec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>FltDecodeParameters FltDecodeParameters FltQue...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>FltDecodeParameters FltDecodeParameters FltQue...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  APIs  target\n",
       "0                                                            0\n",
       "1                                                            0\n",
       "2                                                            0\n",
       "3                                                            0\n",
       "4    FltDecodeParameters FltDecodeParameters FltDec...       0\n",
       "..                                                 ...     ...\n",
       "453                                                          0\n",
       "454  FltDecodeParameters FltDecodeParameters FltDec...       0\n",
       "455                                                          0\n",
       "456  FltDecodeParameters FltDecodeParameters FltQue...       1\n",
       "457  FltDecodeParameters FltDecodeParameters FltQue...       0\n",
       "\n",
       "[458 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(corpus, columns=['APIs'])\n",
    "df['target'] = np.concatenate(attr['target_arr'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "to_array not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n\u001b[0;32m      4\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124midf\u001b[39m\u001b[38;5;124m'\u001b[39m, TfidfVectorizer(ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)))])\n\u001b[1;32m----> 6\u001b[0m df2 \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAPIs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_array\u001b[49m()\n\u001b[0;32m      7\u001b[0m df2\n",
      "File \u001b[1;32mE:\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py:687\u001b[0m, in \u001b[0;36mspmatrix.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetnnz()\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 687\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(attr \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: to_array not found"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "pipe = Pipeline([('idf', TfidfVectorizer(ngram_range=(2, 2)))])\n",
    "\n",
    "df2 = pipe.fit_transform(df['APIs']).to_array()\n",
    "df2\n",
    "#df2[df2.any(axis=1)] ## remove processes with all 0's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                       \n",
       "1                                                       \n",
       "2                                                       \n",
       "3                                                       \n",
       "4      ntfindatom keusermodecallback fsrtlgetfilesize...\n",
       "                             ...                        \n",
       "453                                                     \n",
       "454    ntfindatom keusermodecallback obreferenceobjec...\n",
       "455    ntfindatom keusermodecallback fsrtlgetfilesize...\n",
       "456    ntfindatom keusermodecallback psqueryprocessat...\n",
       "457    ntfindatom keusermodecallback psqueryprocessat...\n",
       "Name: APIs, Length: 458, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['APIs'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "vec shape: (458, 279)\n",
      "NGRAM 1:1 VARIANCE SUM | 0.505\n",
      "(1, 2)\n",
      "vec shape: (458, 847)\n",
      "NGRAM 1:2 VARIANCE SUM | 0.462\n",
      "(1, 3)\n",
      "vec shape: (458, 1657)\n",
      "NGRAM 1:3 VARIANCE SUM | 0.431\n",
      "(1, 4)\n",
      "vec shape: (458, 2682)\n",
      "NGRAM 1:4 VARIANCE SUM | 0.407\n",
      "(2, 2)\n",
      "vec shape: (458, 568)\n",
      "NGRAM 2:2 VARIANCE SUM | 0.418\n",
      "(2, 3)\n",
      "vec shape: (458, 1378)\n",
      "NGRAM 2:3 VARIANCE SUM | 0.393\n",
      "(2, 4)\n",
      "vec shape: (458, 2403)\n",
      "NGRAM 2:4 VARIANCE SUM | 0.373\n",
      "(3, 3)\n",
      "vec shape: (458, 810)\n",
      "NGRAM 3:3 VARIANCE SUM | 0.369\n",
      "(3, 4)\n",
      "vec shape: (458, 1835)\n",
      "NGRAM 3:4 VARIANCE SUM | 0.351\n",
      "(4, 4)\n",
      "vec shape: (458, 1025)\n",
      "NGRAM 4:4 VARIANCE SUM | 0.332\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import PCA, SparsePCA, TruncatedSVD\n",
    "\n",
    "ngram = (1, 4)\n",
    "min_df = 2\n",
    "n = 2\n",
    "\n",
    "def generate_ngrams(corpus, ngram=None, min_df=2, n=2):\n",
    "    \n",
    "    if isinstance(ngram, tuple):\n",
    "        start, finish = 1, 1\n",
    "    else:\n",
    "        start, finish = 4, 4\n",
    "    \n",
    "    for i in range(start):\n",
    "        for j in range(i, finish):\n",
    "            \n",
    "            ngram = (i + 1, j + 1)# if ngram is None else ngram\n",
    "            print(ngram)\n",
    "            # idf vectorizer\n",
    "            vectorizer = TfidfVectorizer(ngram_range=ngram, min_df=min_df)\n",
    "            \n",
    "            # ngram vectorizer\n",
    "            #vectorizer = CountVectorizer(ngram_range=ngram, min_df=2)\n",
    "\n",
    "            vec = vectorizer.fit_transform(corpus)\n",
    "            print(f\"vec shape: {vec.shape}\")\n",
    "            svd = TruncatedSVD(n_components=n, n_iter=5).fit(vec)\n",
    "            var = svd.explained_variance_ratio_\n",
    "            print(f\"NGRAM {i+1}:{j+1} VARIANCE SUM | {svd.explained_variance_ratio_.sum():.3f}\")\n",
    "            x_transformed = svd.transform(vec)\n",
    "            \n",
    "    return x_transformed, var\n",
    "            \n",
    "vec, var = generate_ngrams(corpus, ngram=None, min_df=min_df, n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gat",
   "language": "python",
   "name": "gat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
