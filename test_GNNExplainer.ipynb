{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.datasets import Planetoid, FacebookPagePage\n",
    "from torch_geometric.transforms import RandomNodeSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from lightning.pytorch.utilities.types import TRAIN_DATALOADERS\n",
    "\n",
    "from torch_geometric.datasets import Planetoid, FacebookPagePage\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class BenchmarkDataModule(L.LightningDataModule):\n",
    "    def __init__(self, run_name, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model_name = run_name\n",
    "        self.batch_size = 128\n",
    "        self.num_workers = 3\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \n",
    "        # select model name and load config\n",
    "        if self.model_name == 'Facebook':\n",
    "            data = FacebookPagePage(root='data/',\n",
    "                    transform=RandomNodeSplit(\n",
    "                        split='train_rest', num_val=1_000, num_test=.8))[0]\n",
    "\n",
    "        elif self.model_name in ('Cora', 'CiteSeer'):\n",
    "            data = Planetoid(root='data/', name=self.model_name, split='full')[0]\n",
    "\n",
    "        else: \n",
    "            raise BaseException(\"Dataset not found\")\n",
    "\n",
    "        # set attributes of the datset \n",
    "        self.in_dims = data.x.shape[1]\n",
    "        self.num_classes = data.y.max().item() + 1\n",
    "        self.data = (data,)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.data, batch_size=self.batch_size, pin_memory=True,\n",
    "                           persistent_workers=True, shuffle=False, num_workers=self.num_workers)\n",
    "    # same as train dataloader\n",
    "    def val_dataloader(self):\n",
    "        return self.train_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.utilities.types import OptimizerLRScheduler\n",
    "import torch\n",
    "\n",
    "from models.definitions.layers import ComplexityGNN\n",
    "\n",
    "class LightningGATClassifier(L.LightningModule):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "        self.lr = cfg['lr']\n",
    "        \n",
    "        # load model\n",
    "        self.model = ComplexityGNN(cfg=cfg).to(self.device)\n",
    "\n",
    "        # weight for class imbalance\n",
    "        #weight = torch.tensor([1., 2.], device=self.device)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        self.configure_optimizers()\n",
    "\n",
    "\n",
    "    def forward(self, batch):\n",
    "\n",
    "        # unravel batch\n",
    "        X, y = batch.x.to(self.device), batch.y.to(self.device)\n",
    "        edge_index = batch.edge_index.to(self.device)\n",
    "        return self.model(X, y, edge_index), y\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch):\n",
    "\n",
    "        # fetch mask\n",
    "        mask = batch.train_mask\n",
    "\n",
    "        # feed forward and loss\n",
    "        logits, y = self(batch)\n",
    "        loss = self.criterion(logits[mask], y[mask])\n",
    "\n",
    "        # predictions and accuracy\n",
    "        predictions = torch.argmax(logits[mask], dim=1)\n",
    "        accuracies = torch.sum(predictions == y[mask]).item() / len(y[mask])\n",
    "\n",
    "        # logging\n",
    "        self.log('train_loss', loss, on_epoch=True)\n",
    "        self.log('train_acc', accuracies, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def validation_step(self, batch):\n",
    "\n",
    "        # fetch mask\n",
    "        mask = batch.val_mask\n",
    "\n",
    "        # feed forward and loss\n",
    "        logits, y = self(batch)\n",
    "        loss = self.criterion(logits[mask], y[mask])\n",
    "\n",
    "        # predictions and accuracy\n",
    "        predictions = torch.argmax(logits[mask], dim=1)\n",
    "        accuracies = torch.sum(predictions == y[mask]).item() / len(y[mask])\n",
    "\n",
    "        #logging\n",
    "        self.log('val_loss', loss, on_epoch=True)\n",
    "        self.log('val_acc', accuracies, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.scheduler = {\n",
    "            \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer,\n",
    "                mode=\"min\",  # reduced when the val_acc has stopped decreasing\n",
    "                factor=0.2,  # factor by which the learning rate will be reduced\n",
    "                patience=2,  # number of epochs with no improvement\n",
    "                min_lr=1e-6, # lower bound on the learning rate\n",
    "                verbose=True,\n",
    "            ),\n",
    "            \"monitor\": \"val_loss\"\n",
    "        }\n",
    "        return [self.optimizer], [self.scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import mlflow\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "def objective(trial):\n",
    "    with mlflow.start_run(nested=True):\n",
    "\n",
    "        # set hyperparameters and combine with model config\n",
    "        params = {\n",
    "            'lr' : trial.suggest_loguniform('lr', 1e-4, 1e-1),\n",
    "            'use_fd' : trial.suggest_categorical('trial', [True, False]),\n",
    "            'ngram' : trial.suggest_categorical('ngram', [1, 2, 3]),\n",
    "            \"norm\": trial.suggest_categorical(\"norm\", [1, 2, 3]),\n",
    "            'layer_type': trial.suggest_categorical('layer_type', [GCNConv, GATConv]),\n",
    "        }\n",
    "        model_cfg.update(params)\n",
    "\n",
    "        if model_cfg['use_fd']:\n",
    "            model_cfg['fd_layers'] = trial.suggest_categorical('fd_layers', [[0], [0,1], [1]])\n",
    "            model_cfg['gyration'] = trial.suggest_categorical('gyration', [True, False])\n",
    "        else:\n",
    "            model_cfg['use_fd'] = None\n",
    "            model_cfg['gyration'] = None\n",
    "\n",
    "        # init model\n",
    "        model = LightningGATClassifier(cfg=model_cfg)\n",
    "        datamodule = BenchmarkDataModule(cfg=dataset_cfg)\n",
    "\n",
    "        # init trainer\n",
    "        trainer = L.Trainer(\n",
    "            logger=True,\n",
    "            enable_checkpointing=False,\n",
    "            max_epochs=5,\n",
    "            accelerator=\"gpu\",\n",
    "            devices=1,\n",
    "            callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\")],\n",
    "        )\n",
    "        mlflow.log_params(model_cfg)\n",
    "        trainer.fit(model, datamodule=datamodule)\n",
    "\n",
    "    return trainer.callback_metrics[\"val_acc\"].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the experiment ID if it exists, otherwise create it\n",
    "def get_or_create_experiment(experiment_name):\n",
    "    if experiment := mlflow.get_experiment_by_name(experiment_name):\n",
    "        return experiment.experiment_id\n",
    "    else:\n",
    "        return mlflow.create_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenbr\\AppData\\Local\\Temp\\ipykernel_2348\\627933896.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lr' : trial.suggest_loguniform('lr', 1e-4, 1e-1),\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | ComplexityGNN    | 23.1 K\n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "23.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.1 K    Total params\n",
      "0.093     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.17it/s, v_num=48]           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  9.85it/s, v_num=48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | ComplexityGNN    | 23.2 K\n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "23.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.2 K    Total params\n",
      "0.093     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  9.49it/s, v_num=49]           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | ComplexityGNN    | 23.1 K\n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "23.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.1 K    Total params\n",
      "0.093     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 12.87it/s, v_num=50]           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 11.95it/s, v_num=50]\n"
     ]
    }
   ],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "cfg = dict(\n",
    "    run_name = \"Cora\",\n",
    "    batch_size = 256,\n",
    "    num_workers = 4,\n",
    ")\n",
    "\n",
    "datamodule = BenchmarkDataModule(cfg=cfg)\n",
    "datamodule.setup()\n",
    "\n",
    "model_cfg = {\n",
    "    'arch': [datamodule.in_dims, 16, 8],\n",
    "    'num_classes': datamodule.num_classes,\n",
    "    \"k\": 4,\n",
    "    \"skip\": 1,\n",
    "    \"gyration\": True,\n",
    "    \"norm\": 1.,\n",
    "    'features': 'stack',\n",
    "    \"use_weight\": True,\n",
    "    'layer_type': GATConv,\n",
    "}\n",
    "model_cfg.update(dataset_cfg)\n",
    "\n",
    "\n",
    "\n",
    "# Auto log all MLflow entities\n",
    "mlflow.pytorch.autolog(silent=True)\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Create a new MLflow Experiment\n",
    "experiment_name = \"GAT Workflow\"\n",
    "experiment_id = get_or_create_experiment(experiment_name)\n",
    "mlflow.set_experiment(experiment_id=experiment_id)\n",
    "\n",
    "# main run\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name=run_name, nested=True):\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main run script for training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch_pyfunc = mlflow.pyfunc.load_model(model_uri=model_info.model_uri)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b8a9587fcc1cbb7c2af2866467424141d18584483c14e975ff55eb57b0fa000"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
