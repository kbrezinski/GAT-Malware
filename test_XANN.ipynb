{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4a10555",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a4ab2ff-a4ae-42a6-a194-c745db810730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\envs\\gat\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.definitions.FD import MassFD\n",
    "from utils.utils import get_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a622f9e-6a57-4100-bf9a-697bb70bec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.nn import Linear, Identity\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, model_cfg):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        in_dim = model_cfg[\"in_dim\"]\n",
    "        hid_dim = model_cfg[\"hid_dim\"]\n",
    "        self.use_df = model_cfg[\"use_fd\"]\n",
    "        \n",
    "        # exposed setting for tuning\n",
    "        self.fd = \\\n",
    "            MassFD(\n",
    "                k=model_cfg['k'],\n",
    "                skip=model_cfg['skip'],\n",
    "                gyration=model_cfg['gyration'],\n",
    "                use_weight=model_cfg['use_weight'],\n",
    "                norm=model_cfg['norm'])\n",
    "\n",
    "        # hidden layers and activations\n",
    "        self.l1 = Linear(in_dim, hid_dim)\n",
    "        self.l2 = Linear(hid_dim, hid_dim)\n",
    "        self.l3 = Linear(hid_dim, 2)\n",
    "\n",
    "    def forward(self, x, y=None, edge_index=None, writer=None, epoch=None):\n",
    "\n",
    "        fd = torch.tensor([0])\n",
    "\n",
    "        # first layer\n",
    "        x = self.l1(x)\n",
    "\n",
    "        # fd forward pass\n",
    "        if self.use_df:\n",
    "            fd = self.fd(x, y)\n",
    "            x = x + fd\n",
    "            # log value/weight\n",
    "            if writer is not None:\n",
    "                writer.add_scalar(\"fd_value\", fd, epoch)\n",
    "\n",
    "        # final activation + layers\n",
    "        x = self.l2(x).relu()\n",
    "        logits = self.l3(x)\n",
    "        return logits\n",
    "\n",
    "def train_loop(X, Y, cfg, edge_index=False):\n",
    "\n",
    "    all_scores = {\n",
    "        \"loss_use_fd\": [],\n",
    "        \"loss_no_fd\": [],\n",
    "        \"acc_use_fd\": [],\n",
    "        \"acc_no_fd\": [],\n",
    "    }\n",
    "\n",
    "    #shutil.rmtree(\"runs\")\n",
    "    writer = SummaryWriter() if cfg['use_writer'] else None\n",
    "\n",
    "    for use_fd in [True, False]:\n",
    "        cfg['use_fd'] = use_fd\n",
    "        iter_losses, iter_accs = [], []\n",
    "        for iter in range(cfg['iterations']):\n",
    "            \n",
    "            model = cfg['model_type'](cfg=cfg)\n",
    "            if iter == 0 and use_fd: print(model)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=cfg['lr'])\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "            epoch_losses, epoch_accs = [], []\n",
    "\n",
    "            for epoch in range(cfg['epochs']):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                logits = model(\n",
    "                    x=X, y=Y,\n",
    "                    edge_index=edge_index,\n",
    "                    writer=writer, epoch=epoch)\n",
    "\n",
    "                loss = criterion(logits, Y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                predictions = torch.argmax(logits, dim=1)\n",
    "                accuracies = torch.sum(predictions == Y).item() / len(Y)\n",
    "\n",
    "                epoch_losses.append(loss.item())\n",
    "                epoch_accs.append(accuracies)\n",
    "\n",
    "                # summary writing\n",
    "                if not cfg['use_writer'] or iter != 0: continue\n",
    "\n",
    "                writer.add_scalar(\"loss\", loss, epoch)\n",
    "                for name, param in model.named_parameters():\n",
    "                    writer.add_histogram(f'{\"use_fd\" if use_fd else \"no_fd\"}.{name}', param, epoch)\n",
    "                    writer.add_histogram(f'{\"use_fd\" if use_fd else \"no_fd\"}.{name}.grad', param.grad, epoch)\n",
    "            \n",
    "            iter_losses.append(epoch_losses)\n",
    "            iter_accs.append(epoch_accs)\n",
    "\n",
    "            print(f\"Finished {cfg['iterations']} with {use_fd=}\")\n",
    "\n",
    "        all_scores[\"loss_use_fd\" if use_fd else \"loss_no_fd\"] = iter_losses\n",
    "        all_scores[\"acc_use_fd\" if use_fd else \"acc_no_fd\"] = iter_accs\n",
    "\n",
    "    # final return as numpy arrays\n",
    "    return {k : np.array(v) for k, v in all_scores.items()} \n",
    "\n",
    "\n",
    "def get_dataset(cfg):\n",
    "    X, Y = get_blobs(\n",
    "        feature_dim=cfg['in_dim'],\n",
    "        num_samples=cfg['num_samples'],\n",
    "        split=0.9,\n",
    "        cluster_std=[1., .8],\n",
    "        transform=None,\n",
    "        plot=False)\n",
    "\n",
    "    return torch.tensor(X, dtype=torch.float32), \\\n",
    "            torch.tensor(Y, dtype=torch.long)\n",
    "\n",
    "def plot_scores(all_scores, cfg):\n",
    "\n",
    "    x = np.arange(0, cfg['epochs'], 2)\n",
    "    y = all_scores['no_fd'].mean(axis=0)\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.plot(x, y, '--rs', label=\"Fractal Dimension Model\", markerfacecolor='none')\n",
    "    error = all_scores['no_fd'].std(axis=0)\n",
    "    plt.fill_between(x, y-error, y+error, alpha=0.2, color='r')\n",
    "    print(f\"no_fd {y[-1]=} {error[-1]=}\")\n",
    "\n",
    "    y = all_scores['use_fd'].mean(axis=0)\n",
    "    plt.plot(x, y, '--bo', label=\"Vanilla Model\", markerfacecolor='none')\n",
    "    error = all_scores['use_fd'].std(axis=0)\n",
    "    plt.fill_between(x, y-error, y+error, alpha=0.2, color='b')\n",
    "    print(f\"fd {y[-1]=} {error[-1]=}\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"Training Epoch\")\n",
    "    plt.ylabel(\"Training Loss\")\n",
    "    plt.xlim(0, cfg['epochs'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ae96104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XANN(\n",
      "  (layers): ModuleList(\n",
      "    (0): MassFD(k=4, skip=0, gyration=True, use_weight=True, fd_diff=True)\n",
      "    (1): GCNConv(1433, 32)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): GCNConv(32, 16)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Linear(in_features=16, out_features=7, bias=True)\n",
      "  )\n",
      ")\n",
      "Finished iteration use_fd=True | 5\n",
      "Finished iteration use_fd=True | 5\n",
      "Finished iteration use_fd=True | 5\n",
      "Finished iteration use_fd=True | 5\n",
      "Finished iteration use_fd=True | 5\n",
      "Finished iteration use_fd=False | 5\n",
      "Finished iteration use_fd=False | 5\n",
      "Finished iteration use_fd=False | 5\n",
      "Finished iteration use_fd=False | 5\n",
      "Finished iteration use_fd=False | 5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 69\u001b[0m\n\u001b[0;32m     49\u001b[0m num_classes \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39my\u001b[39m.\u001b[39mmax()\u001b[39m.\u001b[39mitem() \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     51\u001b[0m model_cfg \u001b[39m=\u001b[39m {\n\u001b[0;32m     52\u001b[0m         \u001b[39m'\u001b[39m\u001b[39march\u001b[39m\u001b[39m'\u001b[39m: [in_dims, \u001b[39m32\u001b[39m, \u001b[39m16\u001b[39m],\n\u001b[0;32m     53\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mnum_classes\u001b[39m\u001b[39m'\u001b[39m: num_classes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m'\u001b[39m: XANN\n\u001b[0;32m     67\u001b[0m         } \n\u001b[1;32m---> 69\u001b[0m all_scores \u001b[39m=\u001b[39m train_loop(X\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49mx, Y\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49my, cfg\u001b[39m=\u001b[39;49mmodel_cfg,\n\u001b[0;32m     70\u001b[0m                         edge_index\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49medge_index)\n\u001b[0;32m     71\u001b[0m plot_scores(all_scores, model_cfg)\n",
      "Cell \u001b[1;32mIn[11], line 108\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(X, Y, cfg, edge_index)\u001b[0m\n\u001b[0;32m    105\u001b[0m     all_scores[\u001b[39m\"\u001b[39m\u001b[39mloss_use_fd\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m use_fd \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mloss_no_fd\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m iter_losses\n\u001b[0;32m    106\u001b[0m     all_scores[\u001b[39m\"\u001b[39m\u001b[39macc_use_fd\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m use_fd \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39macc_no_fd\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m iter_accs\n\u001b[1;32m--> 108\u001b[0m all_scores_arr \u001b[39m=\u001b[39m {np\u001b[39m.\u001b[39marray(k): v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m all_scores\u001b[39m.\u001b[39mitems()} \n\u001b[0;32m    109\u001b[0m \u001b[39mreturn\u001b[39;00m all_scores_arr\n",
      "Cell \u001b[1;32mIn[11], line 108\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    105\u001b[0m     all_scores[\u001b[39m\"\u001b[39m\u001b[39mloss_use_fd\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m use_fd \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mloss_no_fd\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m iter_losses\n\u001b[0;32m    106\u001b[0m     all_scores[\u001b[39m\"\u001b[39m\u001b[39macc_use_fd\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m use_fd \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39macc_no_fd\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m iter_accs\n\u001b[1;32m--> 108\u001b[0m all_scores_arr \u001b[39m=\u001b[39m {np\u001b[39m.\u001b[39marray(k): v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m all_scores\u001b[39m.\u001b[39mitems()} \n\u001b[0;32m    109\u001b[0m \u001b[39mreturn\u001b[39;00m all_scores_arr\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear, ReLU\n",
    "from torch_geometric.nn import Sequential, GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "class XANN(torch.nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(XANN, self).__init__()\n",
    "\n",
    "        layer_dims = cfg['arch']\n",
    "        fd_layers = [] if not cfg['use_fd'] else cfg['fd_layers']\n",
    "\n",
    "        # create the layers\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i, (in_d, out_d) in enumerate(zip(layer_dims[:-1], layer_dims[1:])):\n",
    "\n",
    "            # append fd layer if needed\n",
    "            if i in fd_layers:\n",
    "                self.layers.append(MassFD(**cfg))\n",
    "\n",
    "            # append layers\n",
    "            self.layers.append(GCNConv(in_d, out_d))\n",
    "            \n",
    "            # append activation\n",
    "            self.layers.append(ReLU(inplace=True))\n",
    "        \n",
    "        if fd_layers and fd_layers[-1] == len(layer_dims) - 1:\n",
    "            self.layers.append(MassFD(**cfg))\n",
    "        self.layers.append(Linear(out_d, cfg['num_classes']))\n",
    "\n",
    "    def forward(self, x, y, edge_index, writer=None, epoch=None):\n",
    "\n",
    "        # forward pass\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, GCNConv):\n",
    "                x = layer(x, edge_index)\n",
    "            elif isinstance(layer, (ReLU, Linear)):\n",
    "                x = layer(x)\n",
    "            else:\n",
    "                fd = layer(x, y)\n",
    "                x = x + fd\n",
    "                # log value/weight\n",
    "                if writer is not None:\n",
    "                    writer.add_scalar(\"fd_value\", fd, epoch)    \n",
    "        return x\n",
    "\n",
    "# load the data\n",
    "data = Planetoid(root='.', name='Cora')[0]\n",
    "in_dims = data.x.shape[1]\n",
    "num_classes = data.y.max().item() + 1\n",
    "\n",
    "model_cfg = {\n",
    "        'arch': [in_dims, 32, 16],\n",
    "        'num_classes': num_classes,\n",
    "        'fd_layers': [0],\n",
    "        'fd_diff': True,\n",
    "        'num_samples': 500,\n",
    "        \"k\": 4,\n",
    "        \"skip\": 0,\n",
    "        \"gyration\": True,\n",
    "        \"use_weight\": True,\n",
    "        \"norm\": 1.,\n",
    "        'use_writer': True,\n",
    "        'iterations': 5,\n",
    "        'epochs': 40,\n",
    "        'lr': 5e-3,\n",
    "        'model_type': XANN\n",
    "        } \n",
    "\n",
    "all_scores = train_loop(X=data.x, Y=data.y, cfg=model_cfg,\n",
    "                        edge_index=data.edge_index)\n",
    "plot_scores(all_scores, model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1798609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from itertools import product\n",
    "\n",
    "# test multiple configurations\n",
    "\n",
    "cfg = dict(\n",
    "    in_dims = [10**i for i in range(2, 5)],\n",
    "    hid_dims = [i**2 for i in range(5, 8)],\n",
    "    ks = list(range(3, 6)),\n",
    "    skips = [0, 1],\n",
    "    gyrations = [True, False],\n",
    "    use_weight = [True],\n",
    "    norms = [1., 2.],\n",
    "    use_writer = [False],\n",
    "    iterations = [30],\n",
    "    epochs = [20],\n",
    "    lrs = [1e-3, 5e-4, 1e-4, 5e-5])\n",
    "\n",
    "cfg2 = dict(\n",
    "    in_dims = [50],\n",
    "    hid_dims = [64],\n",
    "    ks = [5],\n",
    "    skips = [0],\n",
    "    gyrations = [True],\n",
    "    use_weight = [True],\n",
    "    norms = [1.],\n",
    "    use_writer = [False],\n",
    "    iterations = [30],\n",
    "    epochs = [20],\n",
    "    lrs = [5e-5])\n",
    "\n",
    "hyper_iter = product(*cfg.values())\n",
    "iter_len = len(list(hyper_iter))\n",
    "f = open(f'test_hyper_{iter_len}.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(list(cfg.keys()) + ['no_fd_mean', 'no_fd_std', 'fd_mean', 'fd_std'])\n",
    "\n",
    "for i, (in_dim, hid_dim, k, skip, gyration, _, norm, *_, lr) in enumerate(hyper_iter):\n",
    "\n",
    "    model_cfg = {\n",
    "        'num_samples': 500,\n",
    "        \"in_dim\": in_dim,\n",
    "        \"hid_dim\": hid_dim,\n",
    "        \"k\": k,\n",
    "        \"skip\": skip,\n",
    "        \"gyration\": gyration,\n",
    "        \"use_weight\": True,\n",
    "        \"norm\": norm,\n",
    "        'use_writer': False,\n",
    "        'iterations': 30,\n",
    "        'epochs': 20,\n",
    "        'lr': lr\n",
    "        }   \n",
    "\n",
    "    all_scores = train_loop(*get_dataset(model_cfg), model_cfg)\n",
    "\n",
    "    scores = [all_scores['no_fd'].mean(axis=0)[-1],\n",
    "            all_scores['no_fd'].std(axis=0)[-1],\n",
    "            all_scores['use_fd'].mean(axis=0)[-1],\n",
    "            all_scores['use_fd'].std(axis=0)[-1]]\n",
    "\n",
    "    rows = []\n",
    "    for key, value in model_cfg.items():\n",
    "        rows.append(value)\n",
    "    writer.writerow(rows + scores)\n",
    "\n",
    "\n",
    "    print(f\"Finished iteration {i + 1}\")\n",
    "f.close()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0715eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = MassFD(\n",
    "        k=5,                # number of scales to use\n",
    "        skip=0,             # skip some points on the log-log plot. Helps on occasion for numerical stability in the upper/lower range\n",
    "        gyration=False,     # flag to enable radius of gyration instead of mass-radius\n",
    "        use_weight=False,   # flag to enable the use of weights\n",
    "        norm=2.,            # order of the norm for the minkowski distance \n",
    "        fd_diff=False,      # flag to enable the use of the difference between the FD and the original data\n",
    "        **kwargs)           # any other arguments to pass to the layer\n",
    "layer = layer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6566240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell used for testing fd computation runtime\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from itertools import product\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "n = list(10**i for i in range(4, 6))\n",
    "m = list(i**4 for i in range(3, 9))\n",
    "print(n, m)\n",
    "\n",
    "for n, m in product(n, m):\n",
    "    x, y = get_dataset(cfg=dict(num_samples=n, in_dim=m))\n",
    "\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    %timeit -r 30 -n 10 layer.forward(x=x, y=y)\n",
    "    print(f'Finished {n=}, {m=}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2af5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Sequential(\n",
    "    torch.nn.Linear(10, 32),\n",
    "    MassFD(k=6, gyration=True).\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 16),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(16, 7),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('gat')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "1b8a9587fcc1cbb7c2af2866467424141d18584483c14e975ff55eb57b0fa000"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
