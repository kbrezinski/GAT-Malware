{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4a10555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a4ab2ff-a4ae-42a6-a194-c745db810730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from models.definitions.FD import MassFD\n",
    "\n",
    "from torch.nn import Linear, ReLU\n",
    "from torch_geometric.nn import Sequential, GCNConv, GATConv\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ae96104",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XANN(torch.nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(XANN, self).__init__()\n",
    "\n",
    "        layer_dims = cfg['arch']\n",
    "        fd_layers = [] if not cfg['use_fd'] else cfg['fd_layers']\n",
    "        layer_type = cfg['layer_type']\n",
    "\n",
    "        # create the layers\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i, (in_d, out_d) in enumerate(zip(layer_dims[:-1], layer_dims[1:])):\n",
    "\n",
    "            # append fd layer if needed\n",
    "            if i in fd_layers:\n",
    "                self.layers.append(MassFD(**cfg))\n",
    "\n",
    "            # append layers\n",
    "            self.layers.append(layer_type(in_d, out_d, heads=1))\n",
    "            \n",
    "            # append activation\n",
    "            self.layers.append(ReLU(inplace=True))\n",
    "        \n",
    "        if fd_layers and fd_layers[-1] == len(layer_dims) - 1:\n",
    "            self.layers.append(MassFD(**cfg))\n",
    "        self.layers.append(Linear(out_d, cfg['num_classes']))\n",
    "\n",
    "\n",
    "    def forward(self, x, y, edge_index, writer=None, epoch=None):\n",
    "\n",
    "        # forward pass\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if isinstance(layer, (GCNConv, GATConv)):\n",
    "                x = layer(x, edge_index)\n",
    "            elif isinstance(layer, (ReLU, Linear)):\n",
    "                x = layer(x)\n",
    "            else:\n",
    "                fd = layer(x, y)\n",
    "                x = x + fd\n",
    "                # log value/weight\n",
    "                if writer is not None:\n",
    "                    writer.add_scalar(f'layer{i}.fd_value', fd, epoch)    \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4b0ac31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.data as Data\n",
    "\n",
    "def train_loop(data, cfg):\n",
    "\n",
    "    all_metrics = {\n",
    "        \"use_fd\": [],\n",
    "        \"no_fd\": [],\n",
    "        \"use_fd_val\": [],\n",
    "        \"no_fd_val\": [],\n",
    "    }\n",
    "\n",
    "    #shutil.rmtree(f'runs/{cfg[\"dataset\"]}')\n",
    "    writer = SummaryWriter(log_dir=f'runs/{cfg[\"dataset\"]}') if cfg['use_writer'] else None\n",
    "\n",
    "    # single forward pass\n",
    "    def forward_pass(phase, epoch=0):\n",
    "\n",
    "        for graph in data:\n",
    "            # unravel data\n",
    "            X, y = graph.x, graph.y\n",
    "            edge_index = graph.edge_index\n",
    "\n",
    "            #generate train/val mask\n",
    "            num_nodes = X.shape[0]\n",
    "            train_nodes = int(num_nodes * 0.8)\n",
    "            rand_choice = torch.randperm(num_nodes)\n",
    "            train_mask, val_mask = rand_choice[:train_nodes], rand_choice[train_nodes:]\n",
    "                \n",
    "            # pre-amble\n",
    "            mask = train_mask if phase == \"train\" else val_mask\n",
    "            model.train() if phase == \"train\" else model.eval()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # feed forward\n",
    "            logits = model(\n",
    "                x=X, y=y, edge_index=edge_index,\n",
    "                writer=writer, epoch=epoch)\n",
    "\n",
    "            # loss and backprop\n",
    "            loss = criterion(logits[mask], y[mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # predictions and accuracy\n",
    "            predictions = torch.argmax(logits[mask], dim=1)\n",
    "            accuracies = torch.sum(predictions == y[mask]).item() / len(y[mask])\n",
    "            f1 = f1_score(y[mask], predictions, average='macro')\n",
    "\n",
    "        # summary writing\n",
    "        if cfg['use_writer']:\n",
    "            writer.add_scalar(f'{phase}.{\"use_fd\" if use_fd else \"no_fd\"}.loss', loss, epoch)\n",
    "            for name, param in model.named_parameters():\n",
    "                if name.endswith('weight'): # only capture weights\n",
    "                    writer.add_histogram(f'{phase}.{\"use_fd\" if use_fd else \"no_fd\"}.{name}', param, epoch)\n",
    "                    writer.add_histogram(f'{phase}.{\"use_fd\" if use_fd else \"no_fd\"}.{name}.grad', param.grad, epoch)\n",
    "\n",
    "        return [loss.item(), accuracies, f1]\n",
    "\n",
    "    # start of training loop\n",
    "    for use_fd in [True, False]:\n",
    "        cfg['use_fd'] = use_fd\n",
    "        iter_metrics = []\n",
    "        for iter in range(cfg['iterations']):\n",
    "            \n",
    "            model = XANN(cfg=cfg)\n",
    "            #if iter == 0 and use_fd: print(model)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=cfg['lr'])\n",
    "            criterion = torch.nn.CrossEntropyLoss(weight=None)#torch.tensor([0.1, 2.]))\n",
    "            metrics = []\n",
    "\n",
    "            for epoch in range(cfg['epochs']):\n",
    "                # training loop\n",
    "                train_metrics = forward_pass(phase=\"train\", epoch=epoch)\n",
    "                # val loop every epoch\n",
    "                val_metrics = forward_pass(phase=\"val\", epoch=epoch)\n",
    "                metrics.append(train_metrics + val_metrics)\n",
    "            \n",
    "            iter_metrics.append(metrics)\n",
    "        print(f\"Finished with {use_fd=}\")\n",
    "        all_metrics[\"use_fd\" if use_fd else \"no_fd\"] = iter_metrics\n",
    "\n",
    "    # final return as numpy arrays\n",
    "    return {k : np.array(v) for k, v in all_metrics.items()}, writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "611dd710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Palatino Linotype\"\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "def summary_scores(all_scores, cfg, name, plot=False, save=False):\n",
    "    \n",
    "    # test for the mean difference\n",
    "    t_stat, p = ttest_ind(all_scores['no_fd'][:, -1, 3:], all_scores['use_fd'][:, -1, 3:], axis=0)\n",
    "\n",
    "    scores = [name] + \\\n",
    "            all_scores['no_fd'][:, -1, :].mean(0).tolist() + all_scores['no_fd'][:, -1, :].std(0).tolist() + \\\n",
    "            all_scores['use_fd'][:, -1, :].mean(0).tolist() + all_scores['use_fd'][:, -1, :].std(0).tolist() + \\\n",
    "            [t_stat, p]\n",
    "\n",
    "    if save:\n",
    "        with open(f'results/scores_malware.csv', 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "        writer.writerow(scores + list(cfg.values()))\n",
    "\n",
    "    for key in ['use_fd', 'no_fd']:\n",
    "        print(key, np.around(all_scores[key][:, -1, :3].mean(0), decimals=4).tolist())\n",
    "        print(key, np.around(all_scores[key][:, -1, :3].std(0), decimals=4).tolist())\n",
    "    print(t_stat, p)\n",
    "\n",
    "    if plot:\n",
    "        f, axes = plt.subplots(1, 3, figsize=(14, 6))\n",
    "        #f, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "        y_labels = ['Loss', 'Accuracy', 'F1 Score']*2\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for i, ax in enumerate(axes):\n",
    "            x = np.arange(1, cfg['epochs']+1, 1)\n",
    "            y = all_scores['use_fd'].mean(0)[:, i]\n",
    "            ax.plot(x, y, '--rs', label=\"Vanilla Model\", markerfacecolor='none')\n",
    "            error = all_scores['use_fd'].std(0)[:, i]\n",
    "            ax.fill_between(x, y-error, y+error, alpha=0.2, color='r')\n",
    "\n",
    "\n",
    "            y = all_scores['no_fd'].mean(0)[:, i]\n",
    "            ax.plot(x, y, '--bo', label=\"Fractal Dimension Model\", markerfacecolor='none')\n",
    "            error = all_scores['no_fd'].std(0)[:, i]\n",
    "            ax.fill_between(x, y-error, y+error, alpha=0.2, color='b')\n",
    "            \n",
    "            ax.grid()\n",
    "            ax.set_xlabel(\"Training Epoch\" if i < 3 else \"Validation Epoch\")\n",
    "            ax.set_ylabel(y_labels[i])\n",
    "            ax.set_xlim(0, cfg['epochs'])\n",
    "            if i == 0: ax.legend()\n",
    "\n",
    "        plt.savefig(f\"results/{name}.{model_cfg['fd_layers']}.png\", dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a956e156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing .XML files...\n",
      "Finished saving ardamax.file.csv to data\\raw\n",
      "Finished saving asprox.file.csv to data\\raw\n",
      "Finished saving cerber.file.csv to data\\raw\n",
      "Finished saving cryptowall.file.csv to data\\raw\n",
      "Finished saving dyre.file.csv to data\\raw\n",
      "Finished saving grayfish.file.csv to data\\raw\n",
      "Finished saving kelihos.file.csv to data\\raw\n",
      "Finished saving wannacry.file.csv to data\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ardamax.file.csv\n",
      "asprox.file.csv\n",
      "cerber.file.csv\n",
      "cryptowall.file.csv\n",
      "dyre.file.csv\n",
      "grayfish.file.csv\n",
      "kelihos.file.csv\n",
      "wannacry.file.csv\n",
      "{'layer_type': <class 'torch_geometric.nn.conv.gcn_conv.GCNConv'>, 'arch': [1666, 64, 32], 'num_classes': 2, 'fd_layers': [0, 1], 'fd_diff': True, 'k': 5, 'skip': 1, 'gyration': True, 'use_weight': True, 'norm': 1.0, 'use_writer': True, 'iterations': 1, 'epochs': 30, 'lr': 0.0005, 'dataset': 'file', 'gen_graph': False}\n",
      "Finished with use_fd=True\n",
      "Finished with use_fd=False\n",
      "Processing .XML files...\n",
      "Finished saving ardamax.reg.csv to data\\raw\n",
      "Finished saving asprox.reg.csv to data\\raw\n",
      "Finished saving cerber.reg.csv to data\\raw\n",
      "Finished saving cryptowall.reg.csv to data\\raw\n",
      "Finished saving dyre.reg.csv to data\\raw\n",
      "Finished saving grayfish.reg.csv to data\\raw\n",
      "Finished saving kelihos.reg.csv to data\\raw\n",
      "Finished saving wannacry.reg.csv to data\\raw\n",
      "ardamax.reg.csv\n",
      "asprox.reg.csv\n",
      "cerber.reg.csv\n",
      "cryptowall.reg.csv\n",
      "dyre.reg.csv\n",
      "grayfish.reg.csv\n",
      "kelihos.reg.csv\n",
      "wannacry.reg.csv\n",
      "{'layer_type': <class 'torch_geometric.nn.conv.gcn_conv.GCNConv'>, 'arch': [1666, 64, 32], 'num_classes': 2, 'fd_layers': [0, 1], 'fd_diff': True, 'k': 5, 'skip': 1, 'gyration': True, 'use_weight': True, 'norm': 1.0, 'use_writer': True, 'iterations': 1, 'epochs': 30, 'lr': 0.0005, 'dataset': 'reg', 'gen_graph': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with use_fd=True\n",
      "Finished with use_fd=False\n",
      "Processing .XML files...\n",
      "Finished saving ardamax.thread.csv to data\\raw\n",
      "Finished saving asprox.thread.csv to data\\raw\n",
      "Finished saving cerber.thread.csv to data\\raw\n",
      "Finished saving cryptowall.thread.csv to data\\raw\n",
      "Finished saving dyre.thread.csv to data\\raw\n",
      "Finished saving grayfish.thread.csv to data\\raw\n",
      "Finished saving kelihos.thread.csv to data\\raw\n",
      "Finished saving wannacry.thread.csv to data\\raw\n",
      "ardamax.thread.csv\n",
      "asprox.thread.csv\n",
      "cerber.thread.csv\n",
      "cryptowall.thread.csv\n",
      "dyre.thread.csv\n",
      "grayfish.thread.csv\n",
      "kelihos.thread.csv\n",
      "wannacry.thread.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_type': <class 'torch_geometric.nn.conv.gcn_conv.GCNConv'>, 'arch': [1666, 64, 32], 'num_classes': 2, 'fd_layers': [0, 1], 'fd_diff': True, 'k': 5, 'skip': 1, 'gyration': True, 'use_weight': True, 'norm': 1.0, 'use_writer': True, 'iterations': 1, 'epochs': 30, 'lr': 0.0005, 'dataset': 'thread', 'gen_graph': False}\n",
      "Finished with use_fd=True\n",
      "Finished with use_fd=False\n",
      "Processing .XML files...\n",
      "ardamax.file.csv\n",
      "ardamax.reg.csv\n",
      "ardamax.thread.csv\n",
      "asprox.file.csv\n",
      "asprox.reg.csv\n",
      "asprox.thread.csv\n",
      "cerber.file.csv\n",
      "cerber.reg.csv\n",
      "cerber.thread.csv\n",
      "cryptowall.file.csv\n",
      "cryptowall.reg.csv\n",
      "cryptowall.thread.csv\n",
      "dyre.file.csv\n",
      "dyre.reg.csv\n",
      "dyre.thread.csv\n",
      "grayfish.file.csv\n",
      "grayfish.reg.csv\n",
      "grayfish.thread.csv\n",
      "kelihos.file.csv\n",
      "kelihos.reg.csv\n",
      "kelihos.thread.csv\n",
      "wannacry.file.csv\n",
      "wannacry.reg.csv\n",
      "wannacry.thread.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_type': <class 'torch_geometric.nn.conv.gcn_conv.GCNConv'>, 'arch': [1666, 64, 32], 'num_classes': 2, 'fd_layers': [0, 1], 'fd_diff': True, 'k': 5, 'skip': 1, 'gyration': True, 'use_weight': True, 'norm': 1.0, 'use_writer': True, 'iterations': 1, 'epochs': 30, 'lr': 0.0005, 'dataset': 'all', 'gen_graph': False}\n",
      "Finished with use_fd=True\n",
      "Finished with use_fd=False\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "from utils.data_loading import MalwareDataset\n",
    "from torch_geometric.datasets import Planetoid, FacebookPagePage\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "\n",
    "names = ('file', 'reg', 'thread', 'all')\n",
    "for name in names:\n",
    "    # dataset selection\n",
    "    if name in ('reg', 'file', 'thread', 'all'):\n",
    "        data = MalwareDataset(root='data', cfg={'event_type': name})[0]\n",
    "        in_dims = data[0].x.shape[1]\n",
    "        num_classes = 2\n",
    "    elif name == 'Facebook':\n",
    "        data = FacebookPagePage(root='data/', transform=RandomNodeSplit(split='train_rest', num_val=1_000, num_test=.8))[0]\n",
    "        in_dims = data.x.shape[1]\n",
    "        num_classes = data.y.max().item() + 1\n",
    "        data = (data,)\n",
    "    else:\n",
    "        data = Planetoid(root='data/', name=name, split='full')[0]\n",
    "        in_dims = data.x.shape[1]\n",
    "        num_classes = data.y.max().item() + 1\n",
    "        data = (data,)\n",
    "\n",
    "    model_cfg = {\n",
    "        'layer_type': GCNConv,\n",
    "        'arch': [in_dims, 64, 32],\n",
    "        'num_classes': num_classes,\n",
    "        'fd_layers': [0, 1],\n",
    "        'fd_diff': True,\n",
    "        \"k\": 5,\n",
    "        \"skip\": 1,\n",
    "        \"gyration\": True,\n",
    "        \"use_weight\": True,\n",
    "        \"norm\": 1.,\n",
    "        'use_writer': True,\n",
    "        'iterations': 1,\n",
    "        'epochs': 30,\n",
    "        'lr': 5e-4,\n",
    "        'dataset': name,\n",
    "        'gen_graph': False,\n",
    "        } \n",
    "    print(model_cfg)\n",
    "\n",
    "    all_scores, writer = train_loop(data, cfg=model_cfg)\n",
    "    #summary_scores(all_scores, model_cfg, name=name, plot=True, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f34adbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_scores(all_scores, model_cfg, name=name, plot=True, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0715eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch_geometric\n",
    "\n",
    "def av(d):\n",
    "    return np.around(np.array(list(d.values())).mean(), decimals=4)\n",
    "def mi(d, k=0):\n",
    "    return sorted(list(d.values()))[k]\n",
    "\n",
    "names = ('all',)\n",
    "\n",
    "for name in names:\n",
    "    # dataset selection\n",
    "    if name in ('reg', 'file', 'thread', 'all'):\n",
    "        data = MalwareDataset(root='data', cfg={'event_type': name})[0]\n",
    "        in_dims = data[0].x.shape[1]\n",
    "        num_classes = 2\n",
    "\n",
    "        # compute the average metrics for all graphs in data\n",
    "        metrics = []\n",
    "        for g in data:\n",
    "            G = torch_geometric.utils.to_networkx(g)\n",
    "  \n",
    "            print(f\"{len(G.nodes)=}\")\n",
    "            print(f\"{len(G.edges)=}\")\n",
    "            print(f\"{av(nx.average_neighbor_degree(G))=}\")\n",
    "            print(f\"{mi(nx.average_neighbor_degree(G), k=0)=}\")\n",
    "            print(f\"{mi(nx.average_neighbor_degree(G), k=-1)=}\")\n",
    "            print(f\"{av(nx.average_degree_connectivity(G))=}\")\n",
    "            print(f\"{av(nx.degree_centrality(G))=}\")\n",
    "            print(f\"{nx.degree_assortativity_coefficient(G)=}\")\n",
    "            print(f\"{av(nx.clustering(G))=}\")\n",
    "            print(f\"{nx.density(G)=}\")\n",
    "            print(f\"{nx.transitivity(G)=}\")\n",
    "            print(f\"{av(nx.square_clustering(G))=}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf51d30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('gat')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "1b8a9587fcc1cbb7c2af2866467424141d18584483c14e975ff55eb57b0fa000"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
