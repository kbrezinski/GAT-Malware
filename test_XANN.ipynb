{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4a10555",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a4ab2ff-a4ae-42a6-a194-c745db810730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\envs\\gat\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.definitions.FD import MassFD\n",
    "from utils.utils import get_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "214c4898-8a47-4ee2-8648-7801ee3325be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = get_blobs(\n",
    "        feature_dim=50,\n",
    "        num_samples=500,\n",
    "        split=0.90,\n",
    "        cluster_std=[1., .8],\n",
    "        transform=None,\n",
    "        plot=False)\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "Y = torch.tensor(Y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794cb19e-dcf5-4eb2-94ff-a0b47477391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a622f9e-6a57-4100-bf9a-697bb70bec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "from torch.nn import Linear, Identity\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, use_fd, model_cfg):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        in_dim = model_cfg[\"in_dim\"]\n",
    "        hid_dim = model_cfg[\"hid_dim\"]\n",
    "        self.use_df = use_fd\n",
    "        self.l1 = Linear(in_dim, hid_dim)\n",
    "\n",
    "        # exposed setting for tuning\n",
    "        self.fd_layer = \\\n",
    "            MassFD(\n",
    "                k=model_cfg['k'],\n",
    "                skip=model_cfg['skip'],\n",
    "                gyration=model_cfg['gyration'],\n",
    "                use_weight=model_cfg['use_weight'],\n",
    "                norm=model_cfg['norm'])\n",
    "\n",
    "        # hidden layers and activations\n",
    "        self.l2 = Linear(hid_dim, hid_dim)\n",
    "        self.l3 = Linear(hid_dim, 2)\n",
    "\n",
    "    def forward(self, x, y, writer=None, epoch=None):\n",
    "        \n",
    "        # first layer\n",
    "        x = self.l1(x)\n",
    "\n",
    "        # fd forward pass\n",
    "        if self.use_df:\n",
    "            fd = self.fd_layer(x, y)\n",
    "            x = x + fd\n",
    "            # log value/weight\n",
    "            if writer is not None:\n",
    "                writer.add_scalar(\"fd_value\", fd, epoch)\n",
    "\n",
    "        # final activation + layers\n",
    "        x = self.l2(x).relu()\n",
    "        logits = self.l3(x)\n",
    "        return logits\n",
    "\n",
    "def train_loop(X, Y, model_cfg):\n",
    "\n",
    "    all_scores = {\n",
    "        \"use_fd\": [],\n",
    "        \"no_fd\": [],\n",
    "    }\n",
    "\n",
    "    shutil.rmtree(\"runs\")\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    for use_fd in {True, False}:\n",
    "        iter_scores = []\n",
    "        for iter in range(model_cfg['iterations']):\n",
    "\n",
    "            model = MLP(use_fd=use_fd, model_cfg=model_cfg)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=model_cfg['lr'])\n",
    "            criteron = torch.nn.CrossEntropyLoss()\n",
    "            epoch_scores = []\n",
    "\n",
    "            for epoch in range(model_cfg['epochs']):\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if iter != 0: \n",
    "                    logits = model(X, Y)\n",
    "                else: # log gradients by passing in writer\n",
    "                    logits = model(X, Y, writer=None, epoch=epoch)\n",
    "\n",
    "                loss = criteron(logits, Y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if not epoch % 2:\n",
    "                    #print(f\"Epoch: {epoch:03d} | Loss: {loss.item():.4f}\")\n",
    "                    epoch_scores.append(loss.item())\n",
    "\n",
    "                # summary writing\n",
    "                if not model_cfg['use_writer'] or iter != 0: continue   \n",
    "                if not model_cfg['cfg'] % 5:\n",
    "                    writer.add_scalar(\"loss\", loss, epoch)\n",
    "                    for name, param in model.named_parameters():\n",
    "                        writer.add_histogram(name, param, epoch)\n",
    "                        writer.add_histogram(f'{\"use_fd\" if use_fd else \"no_fd\"}.{name}.grad', param.grad, epoch)\n",
    "        \n",
    "            iter_scores.append(epoch_scores)\n",
    "        all_scores[\"use_fd\" if use_fd else \"no_fd\"] = iter_scores\n",
    "        \n",
    "    all_scores['use_fd'] = np.array(all_scores['use_fd'])\n",
    "    all_scores['no_fd'] = np.array(all_scores['no_fd'])\n",
    "\n",
    "    return all_scores\n",
    "\n",
    "def get_dataset(cfg):\n",
    "    X, Y = get_blobs(\n",
    "        feature_dim=cfg['in_dim'],\n",
    "        num_samples=cfg['num_samples'],\n",
    "        split=0.9,\n",
    "        cluster_std=[1., .8],\n",
    "        transform=None,\n",
    "        plot=False)\n",
    "\n",
    "    return torch.tensor(X, dtype=torch.float32), \\\n",
    "            torch.tensor(Y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1798609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from itertools import product\n",
    "\n",
    "cfg = dict(\n",
    "    in_dims = [10**i for i in range(2, 5)],\n",
    "    hid_dims = [i**2 for i in range(5, 8)],\n",
    "    ks = list(range(3, 6)),\n",
    "    skips = [0, 1],\n",
    "    gyrations = [True, False],\n",
    "    use_weight = [True],\n",
    "    norms = [1., 2.],\n",
    "    use_writer = [False],\n",
    "    iterations = [30],\n",
    "    epochs = [20],\n",
    "    lrs = [1e-3, 5e-4, 1e-4, 5e-5])\n",
    "\n",
    "cfg2 = dict(\n",
    "    in_dims = [50],\n",
    "    hid_dims = [64],\n",
    "    ks = [5],\n",
    "    skips = [0],\n",
    "    gyrations = [True],\n",
    "    use_weight = [True],\n",
    "    norms = [1.],\n",
    "    use_writer = [False],\n",
    "    iterations = [30],\n",
    "    epochs = [20],\n",
    "    lrs = [5e-5])\n",
    "\n",
    "hyper_iter = product(*cfg.values())\n",
    "iter_len = len(list(hyper_iter))\n",
    "f = open(f'test_hyper_{iter_len}.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(list(cfg.keys()) + ['no_fd_mean', 'no_fd_std', 'fd_mean', 'fd_std'])\n",
    "\n",
    "for i, (in_dim, hid_dim, k, skip, gyration, _, norm, *_, lr) in enumerate(hyper_iter):\n",
    "\n",
    "    model_cfg = {\n",
    "        'num_samples': 500,\n",
    "        \"in_dim\": in_dim,\n",
    "        \"hid_dim\": hid_dim,\n",
    "        \"k\": k,\n",
    "        \"skip\": skip,\n",
    "        \"gyration\": gyration,\n",
    "        \"use_weight\": True,\n",
    "        \"norm\": norm,\n",
    "        'use_writer': False,\n",
    "        'iterations': 30,\n",
    "        'epochs': 20,\n",
    "        'lr': lr\n",
    "        }   \n",
    "\n",
    "    all_scores = train_loop(*get_dataset(model_cfg), model_cfg)\n",
    "\n",
    "    scores = [all_scores['no_fd'].mean(axis=0)[-1],\n",
    "            all_scores['no_fd'].std(axis=0)[-1],\n",
    "            all_scores['use_fd'].mean(axis=0)[-1],\n",
    "            all_scores['use_fd'].std(axis=0)[-1]]\n",
    "\n",
    "    rows = []\n",
    "    for key, value in model_cfg.items():\n",
    "        rows.append(value)\n",
    "    writer.writerow(rows + scores)\n",
    "\n",
    "\n",
    "    print(f\"Finished iteration {i + 1}\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fd2bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(0, model_cfg['epochs'], 2)\n",
    "y = all_scores['no_fd'].mean(axis=0)\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(x, y, '--rs', label=\"No FD\", markerfacecolor='none')\n",
    "error = all_scores['no_fd'].std(axis=0)\n",
    "plt.fill_between(x, y-error, y+error, alpha=0.2, color='r')\n",
    "print(f\"no_fd {y[-1]=} {error[-1]=}\")\n",
    "\n",
    "y = all_scores['use_fd'].mean(axis=0)\n",
    "plt.plot(x, y, '--bo', label=\"FD\", markerfacecolor='none')\n",
    "error = all_scores['use_fd'].std(axis=0)\n",
    "plt.fill_between(x, y-error, y+error, alpha=0.2, color='b')\n",
    "print(f\"fd {y[-1]=} {error[-1]=}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlim(0, model_cfg['epochs'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6566240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell used for testing fd computation runtime\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from itertools import product\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "layer = MassFD(\n",
    "        k=5,\n",
    "        skip=0,\n",
    "        gyration=False,\n",
    "        use_weight=False,\n",
    "        norm=2.).to(device)\n",
    "\n",
    "n = list(10**i for i in range(4, 6))\n",
    "m = list(i**4 for i in range(3, 9))\n",
    "print(n, m)\n",
    "\n",
    "for n, m in product(n, m):\n",
    "    x, y = get_dataset(cfg=dict(num_samples=n, in_dim=m))\n",
    "\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    %timeit -r 30 -n 10 layer.forward(x=x, y=y)\n",
    "    print(f'Finished {n=}, {m=}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2af5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('gat')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "1b8a9587fcc1cbb7c2af2866467424141d18584483c14e975ff55eb57b0fa000"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
