{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4a10555",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a4ab2ff-a4ae-42a6-a194-c745db810730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\envs\\gat\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from models.definitions.FD import MassFD\n",
    "from utils.utils import get_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a622f9e-6a57-4100-bf9a-697bb70bec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, ReLU\n",
    "from torch_geometric.nn import Sequential, GCNConv, GATConv\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ae96104",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XANN(torch.nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(XANN, self).__init__()\n",
    "\n",
    "        layer_dims = cfg['arch']\n",
    "        fd_layers = [] if not cfg['use_fd'] else cfg['fd_layers']\n",
    "        layer_type = cfg['layer_type']\n",
    "\n",
    "        # create the layers\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i, (in_d, out_d) in enumerate(zip(layer_dims[:-1], layer_dims[1:])):\n",
    "\n",
    "            # append fd layer if needed\n",
    "            if i in fd_layers:\n",
    "                self.layers.append(MassFD(**cfg))\n",
    "\n",
    "            # append layers\n",
    "            self.layers.append(layer_type(in_d, out_d, heads=1))\n",
    "            \n",
    "            # append activation\n",
    "            self.layers.append(ReLU(inplace=True))\n",
    "        \n",
    "        if fd_layers and fd_layers[-1] == len(layer_dims) - 1:\n",
    "            self.layers.append(MassFD(**cfg))\n",
    "        self.layers.append(Linear(out_d, cfg['num_classes']))\n",
    "\n",
    "\n",
    "    def forward(self, x, y, edge_index, writer=None, epoch=None):\n",
    "\n",
    "        # forward pass\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if isinstance(layer, (GCNConv, GATConv)):\n",
    "                x = layer(x, edge_index)\n",
    "            elif isinstance(layer, (ReLU, Linear)):\n",
    "                x = layer(x)\n",
    "            else:\n",
    "                fd = layer(x, y)\n",
    "                x = x + fd\n",
    "                # log value/weight\n",
    "                if writer is not None:\n",
    "                    writer.add_scalar(f'layer{i}.fd_value', fd, epoch)    \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b0ac31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(data, cfg, edge_index=False):\n",
    "\n",
    "    all_metrics = {\n",
    "        \"use_fd\": [],\n",
    "        \"no_fd\": [],\n",
    "        \"use_fd_val\": [],\n",
    "        \"no_fd_val\": [],\n",
    "    }\n",
    "\n",
    "    #shutil.rmtree(\"runs\")\n",
    "    writer = SummaryWriter(log_dir=f'runs/{cfg[\"dataset\"]}') if cfg['use_writer'] else None\n",
    "\n",
    "    # unravel data\n",
    "    X, y = data.x, data.y\n",
    "    train_mask, val_mask = data.train_mask, data.val_mask\n",
    "\n",
    "    # single forward pass\n",
    "    def forward_pass(phase, epoch=0):\n",
    "        \n",
    "        # pre-amble\n",
    "        mask = train_mask if phase == \"train\" else val_mask\n",
    "        model.train() if phase == \"train\" else model.eval()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(\n",
    "            x=X, y=y, edge_index=edge_index,\n",
    "            writer=writer, epoch=epoch)\n",
    "\n",
    "        loss = criterion(logits[mask], y[mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predictions = torch.argmax(logits[mask], dim=1)\n",
    "        accuracies = torch.sum(predictions == y[mask]).item() / len(y[mask])\n",
    "        f1 = f1_score(y[mask], predictions, average='macro')\n",
    "\n",
    "        # summary writing\n",
    "        if cfg['use_writer']:\n",
    "            writer.add_scalar(f'{phase}.{\"use_fd\" if use_fd else \"no_fd\"}.loss', loss, epoch)\n",
    "            for name, param in model.named_parameters():\n",
    "                if name.endswith('weight'): # only capture weights\n",
    "                    writer.add_histogram(f'{phase}.{\"use_fd\" if use_fd else \"no_fd\"}.{name}', param, epoch)\n",
    "                    writer.add_histogram(f'{phase}.{\"use_fd\" if use_fd else \"no_fd\"}.{name}.grad', param.grad, epoch)\n",
    "\n",
    "        return [loss.item(), accuracies, f1]\n",
    "\n",
    "    # start of training loop\n",
    "    for use_fd in [True, False]:\n",
    "        cfg['use_fd'] = use_fd\n",
    "        iter_metrics = []\n",
    "        for iter in range(cfg['iterations']):\n",
    "            \n",
    "            model = XANN(cfg=cfg)\n",
    "            if iter == 0 and use_fd: print(model)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=cfg['lr'])\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "            metrics = []\n",
    "\n",
    "            for epoch in range(cfg['epochs']):\n",
    "                # training loop\n",
    "                train_metrics = forward_pass(phase=\"train\", epoch=epoch)\n",
    "                # val loop every epoch\n",
    "                val_metrics = forward_pass(phase=\"val\", epoch=epoch)\n",
    "                metrics.append(train_metrics + val_metrics)\n",
    "            \n",
    "            iter_metrics.append(metrics)\n",
    "        print(f\"Finished with {use_fd=}\")\n",
    "        all_metrics[\"use_fd\" if not use_fd else \"no_fd\"] = iter_metrics\n",
    "\n",
    "    # final return as numpy arrays\n",
    "    return {k : np.array(v) for k, v in all_metrics.items()}, writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a956e156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XANN(\n",
      "  (layers): ModuleList(\n",
      "    (0): MassFD(k=5, skip=1, gyration=True, use_weight=True, fd_diff=True)\n",
      "    (1): GATConv(128, 32, heads=1)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): GATConv(32, 16, heads=1)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Linear(in_features=16, out_features=4, bias=True)\n",
      "  )\n",
      ")\n",
      "Finished with use_fd=True\n",
      "Finished with use_fd=False\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "from torch_geometric.datasets import Planetoid, FacebookPagePage\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "\n",
    "name = 'Facebook'\n",
    "# dataset selection\n",
    "if name == 'Facebook':\n",
    "        data = FacebookPagePage(root='data/',\n",
    "                        transform=RandomNodeSplit(split='train_rest', num_val=1_000, num_test=.8))[0]\n",
    "else: data = Planetoid(root='data/', name=name, split='full')[0]\n",
    "in_dims = data.x.shape[1]\n",
    "num_classes = data.y.max().item() + 1\n",
    "\n",
    "model_cfg = {\n",
    "        'layer_type': GATConv,\n",
    "        'arch': [in_dims, 32, 16],\n",
    "        'num_classes': num_classes,\n",
    "        'fd_layers': [1],\n",
    "        'fd_diff': True,\n",
    "        'num_samples': 2000,\n",
    "        \"k\": 5,\n",
    "        \"skip\": 1,\n",
    "        \"gyration\": True,\n",
    "        \"use_weight\": True,\n",
    "        \"norm\": 1.,\n",
    "        'use_writer': True,\n",
    "        'iterations': 1,\n",
    "        'epochs': 50,\n",
    "        'lr': 5e-3,\n",
    "        'dataset': name\n",
    "        } \n",
    "\n",
    "all_scores, writer = train_loop(data, cfg=model_cfg, edge_index=data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "523aa8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenneth\\AppData\\Local\\Temp\\ipykernel_19460\\3708135734.py:18: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  t_stat, p = ttest_ind(all_scores['no_fd'][:, -1, 0], all_scores['use_fd'][:, -1, 0], axis=0)\n",
      "e:\\anaconda3\\envs\\gat\\lib\\site-packages\\scipy\\stats\\_stats_py.py:1253: RuntimeWarning: divide by zero encountered in divide\n",
      "  var *= np.divide(n, n-ddof)  # to avoid error on division by zero\n",
      "e:\\anaconda3\\envs\\gat\\lib\\site-packages\\scipy\\stats\\_stats_py.py:1253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  var *= np.divide(n, n-ddof)  # to avoid error on division by zero\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Palatino Linotype\"\n",
    "\n",
    "def summary_scores(all_scores, cfg, name, plot=False):\n",
    "    assert name in ['citeseer', 'facebook', 'cora'], \"invalid name\"\n",
    "\n",
    "    with open(f'results/scores.csv', 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "    #writer.writerow(['name', 'no_fd_loss_mean_train', 'no_fd_acc_mean_train', 'no_fd_f1_mean_train', 'no_fd_loss_mean_val', 'no_fd_acc_mean_val', 'no_fd_f1_mean_val',\n",
    "    #                         'no_fd_loss_std_train', 'no_fd_acc_std_train', 'no_fd_f1_std_train', 'no_fd_loss_std_val', 'no_fd_acc_std_val', 'no_fd_f1_std_val',\n",
    "    #                         'fd_loss_mean_train', 'fd_acc_mean_train', 'fd_f1_mean_train', 'fd_loss_mean_val', 'fd_acc_mean_val', 'fd_f1_mean_val',\n",
    "    #                         'fd_loss_std_train', 'fd_acc_std_train', 'fd_f1_std_train', 'fd_loss_std_val', 'fd_acc_std_val', 'fd_f1_std_val', 't_test', 'p_value']                       \n",
    "    #                         + list(cfg.keys()))\n",
    "\n",
    "        # test for the mean difference\n",
    "        t_stat, p = ttest_ind(all_scores['no_fd'][:, -1, 0], all_scores['use_fd'][:, -1, 0], axis=0)\n",
    "\n",
    "        scores = [name] + \\\n",
    "                all_scores['no_fd'][:, -1, :].mean(0).tolist() + all_scores['no_fd'][:, -1, :].std(0).tolist() + \\\n",
    "                all_scores['use_fd'][:, -1, :].mean(0).tolist() + all_scores['use_fd'][:, -1, :].std(0).tolist() + \\\n",
    "                [t_stat, p]\n",
    "        writer.writerow(scores + list(cfg.values()))\n",
    "\n",
    "    if plot:\n",
    "        f, axes = plt.subplots(2, 3, figsize=(14, 7))\n",
    "        y_labels = ['Loss', 'Accuracy', 'F1 Score']*2\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for i, ax in enumerate(axes):\n",
    "            x = np.arange(1, cfg['epochs']+1, 1)\n",
    "            y = all_scores['no_fd'].mean(0)[:, i]\n",
    "            ax.plot(x, y, '--rs', label=\"Vanilla Model\", markerfacecolor='none')\n",
    "            error = all_scores['no_fd'].std(0)[:, i]\n",
    "            ax.fill_between(x, y-error, y+error, alpha=0.2, color='r')\n",
    "\n",
    "            y = all_scores['use_fd'].mean(0)[:, i]\n",
    "            ax.plot(x, y, '--bo', label=\"Fractal Dimension Model\", markerfacecolor='none')\n",
    "            error = all_scores['use_fd'].std(0)[:, i]\n",
    "            ax.fill_between(x, y-error, y+error, alpha=0.2, color='b')\n",
    "            \n",
    "            ax.grid()\n",
    "            ax.set_xlabel(\"Training Epoch\" if i < 3 else \"Validation Epoch\")\n",
    "            ax.set_ylabel(y_labels[i])\n",
    "            ax.set_xlim(0, cfg['epochs'])\n",
    "            if i == 0: ax.legend()\n",
    "\n",
    "        plt.savefig(f\"results/{name}.png\", dpi=150, bbox_inches='tight')\n",
    "\n",
    "\n",
    "summary_scores(all_scores, model_cfg, name=\"facebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1798609",
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m writer \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mwriter(f)\n\u001b[0;32m     36\u001b[0m writer\u001b[39m.\u001b[39mwriterow(\u001b[39mlist\u001b[39m(cfg\u001b[39m.\u001b[39mkeys()) \u001b[39m+\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mno_fd_mean\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mno_fd_std\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfd_mean\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfd_std\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 38\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mnext\u001b[39;49m(hyper_iter))\n\u001b[0;32m     40\u001b[0m \u001b[39mfor\u001b[39;00m i, (in_dim, hid_dim, k, skip, gyration, _, norm, \u001b[39m*\u001b[39m_, lr) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(hyper_iter):\n\u001b[0;32m     42\u001b[0m     model_cfg \u001b[39m=\u001b[39m {\n\u001b[0;32m     43\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mnum_samples\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m500\u001b[39m,\n\u001b[0;32m     44\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39min_dim\u001b[39m\u001b[39m\"\u001b[39m: in_dim,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m: lr\n\u001b[0;32m     55\u001b[0m         }   \n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from itertools import product\n",
    "\n",
    "# test multiple configurations\n",
    "\n",
    "cfg = dict(\n",
    "    in_dims = [10**i for i in range(2, 5)],\n",
    "    hid_dims = [i**2 for i in range(5, 8)],\n",
    "    ks = list(range(3, 6)),\n",
    "    skips = [0, 1],\n",
    "    gyrations = [True, False],\n",
    "    use_weight = [True],\n",
    "    norms = [1., 2.],\n",
    "    use_writer = [False],\n",
    "    iterations = [30],\n",
    "    epochs = [20],\n",
    "    lrs = [1e-3, 5e-4, 1e-4, 5e-5])\n",
    "\n",
    "cfg = dict(\n",
    "    in_dims = [50],\n",
    "    hid_dims = [64],\n",
    "    ks = [5, 4],\n",
    "    skips = [0],\n",
    "    gyrations = [True, False],\n",
    "    use_weight = [True],\n",
    "    norms = [1.],\n",
    "    use_writer = [False],\n",
    "    iterations = [30],\n",
    "    epochs = [20],\n",
    "    lrs = [5e-5])\n",
    "\n",
    "hyper_iter = product(*cfg.values())\n",
    "iter_len = len(list(hyper_iter))\n",
    "f = open(f'data/test_hyper_{iter_len}.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(list(cfg.keys()) + ['no_fd_mean', 'no_fd_std', 'fd_mean', 'fd_std'])\n",
    "\n",
    "for i, (in_dim, hid_dim, k, skip, gyration, _, norm, *_, lr) in enumerate(hyper_iter):\n",
    "\n",
    "    model_cfg = {\n",
    "        'num_samples': 500,\n",
    "        \"in_dim\": in_dim,\n",
    "        \"hid_dim\": hid_dim,\n",
    "        \"k\": k,\n",
    "        \"skip\": skip,\n",
    "        \"gyration\": gyration,\n",
    "        \"use_weight\": True,\n",
    "        \"norm\": norm,\n",
    "        'use_writer': False,\n",
    "        'iterations': 30,\n",
    "        'epochs': 20,\n",
    "        'lr': lr\n",
    "        }   \n",
    "\n",
    "    all_scores = train_loop(*get_blobs(model_cfg), model_cfg)\n",
    "\n",
    "    scores = [all_scores['no_fd'].mean(axis=0)[-1],\n",
    "            all_scores['no_fd'].std(axis=0)[-1],\n",
    "            all_scores['use_fd'].mean(axis=0)[-1],\n",
    "            all_scores['use_fd'].std(axis=0)[-1]]\n",
    "\n",
    "    rows = []\n",
    "    for key, value in model_cfg.items():\n",
    "        rows.append(value)\n",
    "    writer.writerow(rows + scores)\n",
    "\n",
    "\n",
    "    print(f\"Finished iteration {i + 1}\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0715eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = MassFD(\n",
    "        k=5,                # number of scales to use\n",
    "        skip=0,             # skip some points on the log-log plot. Helps on occasion for numerical stability in the upper/lower range\n",
    "        gyration=False,     # flag to enable radius of gyration instead of mass-radius\n",
    "        use_weight=False,   # flag to enable the use of weights\n",
    "        norm=2.,            # order of the norm for the minkowski distance \n",
    "        fd_diff=False,      # flag to enable the use of the difference between the FD and the original data\n",
    "        **kwargs)           # any other arguments to pass to the layer\n",
    "layer = layer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6566240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell used for testing fd computation runtime\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from itertools import product\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "n = list(10**i for i in range(4, 6))\n",
    "m = list(i**4 for i in range(3, 9))\n",
    "print(n, m)\n",
    "\n",
    "for n, m in product(n, m):\n",
    "    x, y = get_dataset(cfg=dict(num_samples=n, in_dim=m))\n",
    "\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    %timeit -r 30 -n 10 layer.forward(x=x, y=y)\n",
    "    print(f'Finished {n=}, {m=}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2af5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Sequential(\n",
    "    torch.nn.Linear(10, 32),\n",
    "    MassFD(k=6, gyration=True).\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 16),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(16, 7),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('gat')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "1b8a9587fcc1cbb7c2af2866467424141d18584483c14e975ff55eb57b0fa000"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
