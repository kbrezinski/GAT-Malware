{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "from utils.data_loading import MalwareDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = dict(\n",
    "    event_type=('reg','file','thread'),\n",
    "    ngram=(1, 1),\n",
    "    features='stack',\n",
    "    )\n",
    "\n",
    "datasets = []\n",
    "for name in cfg['event_type']:\n",
    "   # dataset selection \n",
    "    cfg['event_type'] = name\n",
    "    datasets.append(MalwareDataset(root='data', cfg=cfg)[0])\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv, GATConv, Sequential\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, embed_dim=32):\n",
    "        super().__init__()\n",
    "        self.net = Sequential(\n",
    "            \"x, edge_index\",[\n",
    "            (GATConv(-1, embed_dim), 'x, edge_index -> x'),\n",
    "            nn.ReLU(inplace=True),\n",
    "            (GATConv(embed_dim, embed_dim), 'x, edge_index -> x'),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ])\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.net(x, edge_index)\n",
    "\n",
    "class Feedforward(nn.Module):\n",
    "    def __init__(self, hid_dim=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyLinear(hid_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hid_dim, 2),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class EnsembleGNN(nn.Module):\n",
    "    def __init__(self, embed_dim=32):\n",
    "        super().__init__()\n",
    "        self.net1 = GNN(embed_dim)\n",
    "        self.net2 = GNN(embed_dim)\n",
    "        self.net3 = GNN(embed_dim)\n",
    "        self.ff = Feedforward(hid_dim=embed_dim*2)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        d1, d2, d3 = data\n",
    "        x1 = self.net1(d1.x, d1.edge_index)\n",
    "        x2 = self.net2(d2.x, d2.edge_index)\n",
    "        x3 = self.net3(d3.x, d3.edge_index)\n",
    "        # (n, dims) -> (n * 3, dims)\n",
    "        out = torch.cat([x1, x2, x3], dim=0)\n",
    "        out = self.layer_norm(out)\n",
    "        out = self.ff(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\envs\\gat\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, cum_loss=6.3296\n",
      "cum_f1=0.4438, cum_acc=0.6731\n",
      "###################################\n",
      "epoch=100, cum_loss=1.0725\n",
      "cum_f1=0.6609, cum_acc=0.8690\n",
      "###################################\n",
      "epoch=200, cum_loss=0.7793\n",
      "cum_f1=0.7273, cum_acc=0.8735\n",
      "###################################\n",
      "epoch=300, cum_loss=0.7556\n",
      "cum_f1=0.7004, cum_acc=0.8723\n",
      "###################################\n",
      "epoch=400, cum_loss=0.7274\n",
      "cum_f1=0.7127, cum_acc=0.8752\n",
      "###################################\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "model = EnsembleGNN(embed_dim=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(weight=None)#torch.tensor([1., 2.]))\n",
    "\n",
    "for epoch in range(500):\n",
    "    \n",
    "    cum_loss = 0\n",
    "    cum_acc = 0\n",
    "    cum_f1 = 0\n",
    "    num_graphs = len(datasets[0])\n",
    "\n",
    "    # loop through graph models by variant\n",
    "    for data in zip(datasets[0], datasets[1], datasets[2]):\n",
    "        \n",
    "        # zero grad and train\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "\n",
    "        # compute loss and accuracy\n",
    "        labels = torch.cat([d.y for d in data], axis=0)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        cum_loss += loss.item()\n",
    "\n",
    "        # predictions and accuracy\n",
    "        predictions = torch.argmax(out, dim=1)\n",
    "        accuracies = torch.sum(predictions == labels).item() / len(labels)\n",
    "\n",
    "        cum_acc += accuracies\n",
    "        cum_f1 += f1_score(labels.cpu(), predictions.cpu(), average='macro')\n",
    "\n",
    "    #f1 = f1_score(y[mask].cpu(), predictions.cpu(), average='macro')\n",
    "\n",
    "    if not epoch % 100:\n",
    "        print(f\"{epoch=}, {cum_loss=:.4f}\")\n",
    "        print(f\"cum_f1={cum_f1 / num_graphs:.4f}, cum_acc={cum_acc / num_graphs:.4f}\")\n",
    "        print(\"#\"*35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b8a9587fcc1cbb7c2af2866467424141d18584483c14e975ff55eb57b0fa000"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
