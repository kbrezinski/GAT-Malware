
import os
import torch
import glob
import pickle
import pandas as pd
import xml.etree.ElementTree as ET

from torch_geometric.data import InMemoryDataset, Data, HeteroData


from utils.utils import (assign_labels, get_edge_list, get_module_df,
                         get_stack_df, get_feature_vectors)


class MalwareDataset(InMemoryDataset):
    
    def __init__(self, root, cfg, transform=None, pre_transform=None):
        """
        root = where the dataset should be stored
        """
        self.root = root
        self.event_type = cfg['event_type']
        self.transform = transform
        self.ngram = cfg['ngram']
        self.feature_set = cfg['features']
        
        super(MalwareDataset, self).__init__(root, transform, pre_transform)
        
    @property
    def raw_file_names(self):
        XML_PATH = os.path.join(self.root, 'xml')
        # if these files do not exists in /raw, the xml parse is not triggered
        return [filename.rsplit('.', 1)[0] + self.event_type + '.csv' for filename in os.listdir(XML_PATH)]
        
    @property
    def processed_file_names(self):
        # if this file exists in /processed, process is not triggered
        return [f"{self.feature_set}.{self.ngram}.{self.event_type}.pt"] 
    
    def download(self):
        # process the raw xml files if csv files are not present
        self.process_xml(self.root)

    def len(self):
        # only a single list of graphs is stored
        return 1

    def process_xml(self, base_path):
        print("Processing .XML files...")

        # append raw path to base_dir
        XML_PATH = os.path.join(base_path, 'xml')
        
        # loop through .XML files
        for filename in os.listdir(XML_PATH):
            
            # loop through relevent event type xml files
            if (not filename.endswith(f"{self.event_type}.XML")) and (self.event_type != 'all'):
                continue

            # check if the csv file already exists
            file_key_name = filename.rsplit(".", 1)[0] + '.csv'
            if file_key_name in os.listdir(os.path.join(XML_PATH, os.pardir, 'raw')):
                continue

            # get the full path and root of xml file
            path = os.path.join(base_path, 'xml', filename)

            # get the module df; join with stack traces, then formatting
            process_df = get_module_df(path)\
                        .join(get_stack_df(path), how='left')\
                        .reset_index()\
                        .fillna(value={'stack':' '})
                
            # create save dir and save it
            save_dir = os.path.join(base_path, 'raw')
            os.makedirs(save_dir, exist_ok=True)
            
            # get the target name of the malware executable and save it
            target_name = filename.split(".")[0].lower()
            save_name = f'{target_name}.{self.event_type}.csv'

            # create final df
            process_df.to_csv(
                    os.path.join(save_dir, save_name), index=False)
            print(f"Finished saving {save_name} to {save_dir}")

    # main process 
    def process(self):

        # check if the feature set is hetero
        if self.feature_set == 'hetero':
            self.process_hetero()
            return
        
        # parent list for all the executable graphs
        exe_graphs = []
        module_list = []

        # loop through all the files and read csv
        for filename in os.listdir(self.raw_dir):
            
            # check if all is selected, or wrong event type
            if (not filename.endswith(f"{self.event_type}.csv")) and (self.event_type != 'all'):
                continue
            print(f"Processing {filename}...")

            graph_nodes = pd.read_csv(self.raw_dir + '\\' + filename)

            # Assign labels and return array
            target_list = assign_labels(graph_nodes, filename)
            
            # Get the processed feature list
            module_list.append(graph_nodes[self.feature_set])
            # Get the edge list
            edge_list = get_edge_list(graph_nodes)

            # Create the data object
            data = Data(
                y = target_list,
                edge_index = truncate_edges(edge_list, max_nodes=len(target_list)),
            )
            # append to master list
            exe_graphs.append((filename, data))

        # get the tfidf vectors for the modules
        tfidf_modules, vectorizer = get_feature_vectors(module_list, ngram=self.ngram, min_df=1)
        
        for graph, module in zip(exe_graphs, tfidf_modules):
            graph[1].x = module 

        # collate the list and save the data
        torch.save([exe[1] for exe in exe_graphs], self.processed_paths[0])

        # save the vectorizer
        save_name = f"{self.feature_set}.{self.ngram}.{self.event_type}.pkl"
        pickle.dump(vectorizer, open(f"models/binaries/{save_name}", "wb"))


    # process a hetero version of the graph dataset
    def process_hetero(self):

        # parent list for all the executable graphs
        exe_graphs = []
        exe_list = set(name.split(".")[0] for name in os.listdir(self.raw_dir))

        # loop through all the files and read csv
        for exe_name in exe_list:

            # hetero data object for each executable
            data = HeteroData()

            # loop through all the event types for each executable
            for i, file_path in enumerate(glob.glob(f"{self.raw_dir}\\{exe_name}.*.csv")):

                graph_nodes = pd.read_csv(file_path)
                event_type = file_path.split(".")[-2]
                filename = os.path.basename(file_path).split(".")[0]

                # vectorize and create feature matrix
                name = f'stack.{self.ngram}.{event_type}'
                vectorizer = pickle.load(open(f'models/binaries/{name}.pkl', 'rb'))
                X = torch.tensor(vectorizer.transform(graph_nodes['stack']).toarray(), dtype=torch.float)
                data[event_type].x = X

                # only in the first iteration do you process labels and edges
                if i == 0:
                    # Assign labels and return array
                    data.y = assign_labels(graph_nodes, filename)
                    # Get the edge list
                    edge_list = get_edge_list(graph_nodes)
                    edge_list = truncate_edges(edge_list, max_nodes=len(data.y))

                data[event_type].edge_list = edge_list

            # append to master list
            exe_graphs.append(data)
            
        torch.save(exe_graphs, self.processed_paths[0])


    # fetch the data from the .pt file
    def get(self, idx):
        return torch.load(self.processed_paths[0])


def truncate_edges(edge_index, max_nodes):
    # truncate edges to max_nodes: [2, E]
    edge_index = edge_index[:, edge_index[0] < max_nodes]
    edge_index = edge_index[:, edge_index[1] < max_nodes]
    return edge_index


def process_single_xml(path):
   pass